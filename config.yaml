# ✅ User Profile Settings
user_profile:
  medium_username:  "codingoni"
  wix_url: Null  # "https://www.zionadventurephotog.com"
  wordpress_url: Null # https://wordpress.org/news
  target_audience: "Non Technical People Looking For Tech Thought Leadership"  # Replace with your target audience
  professional_summary: "I'm a Software Engineer with a passion for creating innovative solutions and sharing my knowledge with the world. I'm always looking for new ways to improve my skills and help others do the same."  # Replace with your professional summary
  resume_url: "https://www.linkedin.com/in/your-linkedin-url"  # Replace with your LinkedIn URL
  llm:
    Pollinations:
      # Common default settings
      default_model: "openai"
      seed: 42
      temperature: 0.7
      jsonMode: true
      private: true

      # OpenAI-Compatible Completion (POST to /openai)
      openai_compatible:
        endpoint: "/v1/chat/completions"
        model: "text-davinci-003"  # or https://platform.openai.com/docs/models
        prompt: "Your custom prompt"  # Dynamically replaced
        suffix: null
        best_of: 1
        echo: false
        frequency_penalty: 0.0
        presence_penalty: 0.0
        logit_bias: {}  # e.g., {"50256": -100} to block <|endoftext|>
        logprobs: null
        max_tokens: 256
        "n": 1
        seed: 42
        stop: null  # Can be a string or array of strings
        stream: false
        stream_options: null
        temperature: 0.7
        top_p: 1.0
        messages: [
          {"role": "system", "content": "You are a helpful assistant."},
          {"role": "user", "content": "What is artificial intelligence?"}
        ]
        audio: null  # Optional: For models like gpt-4o that can output audio
        function_call: null  # Deprecated in favor of tool_choice, still optional
        functions: []  # Deprecated, use tools instead if needed
        max_completion_tokens: 256  # Use instead of max_tokens for o-series models
        metadata: {}  # Optional: Custom key-value metadata
        modalities: ["text"]  # Or ["text", "audio"] for multimodal models
        parallel_tool_calls: true  # Enable or disable parallel function calls
        prediction: null  # Optional prediction configuration
        reasoning_effort: "medium"  # o-series models only: low | medium | high
        response_format: "json_object"  # JSON schema config or {type: "json_object"}
        service_tier: "auto"  # auto | default (relevant for Scale Tier users)
        store: false  # Whether to store the output for model distillation
        tool_choice: "auto"  # Controls tool usage: none, auto, or function spec
        tools: []  # List of callable functions (OpenAI function calling format)
        top_logprobs: null  # Used only if logprobs is true
        web_search_options: null  # Advanced: for search-augmented completions
        search_context_size: "medium"  # Guidance for search context
        user_location: null  # Structured approximate location for search
        user: "user_id_here"

      # Native Pollinations Completion (POST to /)
      native_post:
        endpoint: "https://text.pollinations.ai/"
        model: "mistral"
        messages:
          - role: "system"
            content: "You're a helpful assistant."
          - role: "user"
            content: "Your User Prompt"
        reasoning_effort: "medium"

      # Simple Pollinations GET Completion
      native_get:
        endpoint: "https://text.pollinations.ai/{prompt}"  # prompt will be URL encoded
        model: "mistral"
        system: "You're a helpful assistant."
        json: true
      
      pollinations_image_get:
        endpoint: "https://image.pollinations.ai/prompt/{prompt}"  # prompt will be URL encoded
        model: "flux"              # Options: flux, flux-realism, flux-anime, turbo, etc.
        seed: 42                   # Controls image randomness
        width: 1024                # Image width in pixels
        height: 1024               # Image height in pixels
        nologo: true               # Remove watermark if true
        private: true              # Make image generation private
        enhance: false             # Enhance quality (if supported)
        safe: true                 # Apply safety filters

    OpenAI:
      name: "gpt-4"
      text_model: "gpt-4o-mini"
      image_model: "dall-e-3"
      image_size: "1024x1024"
      temperature: 0.7  # Adjusts randomness of responses (0 = strict, 1 = creative)
      top_p: 0.95  # Adjusts the likelihood of the text_model generating the top response (0 = no bias, 1 = strict bias)
      response_format: "json" # json | text | auto
      tool: Null
      available_models: # List of available models for this provider Check https://platform.openai.com/docs/api-reference/models
        - "gpt-4o"
        - "gpt-4o-mini"
        - "o1"
        - "o3-mini"
        - "gpt-4.5-preview"
        - "o3-mini-2025-01-31"
        - "o1-2024-12-17"
        - "gpt-4o-mini-2024-07-18"
        - "gpt-4o-2024-11-20"
        - "gpt-4o-2024-08-06"
        - "gpt-4.5-preview-2025-02-27"
        - "gpt-4-turbo-preview"
        - "gpt-4-turbo-2024-04-09"
        - "gpt-4-turbo"
        - "gpt-4-1106-preview"
        - "gpt-4-0613"
        - "gpt-4-0125-preview"
        - "gpt-4"
        - "gpt-3.5-turbo-16k"
        - "gpt-3.5-turbo-1106"
        - "gpt-3.5-turbo-0125"
        - "gpt-3.5-turbo"

    #https://api-docs.deepseek.com/api/create-chat-completion
    DeepSeek:
      text_model: "deepseek-chat"  # Ensure this matches the model you intend to use
      presence_penalty: 0.0  # Float between -2 and 2
      frequency_penalty: 0.0  # Float between -2 and 2
      response_format: "json_object"  # "json_object" or "text"
      temperature: 0.7  # Float ≤ 2
      max_tokens: 500  # Integer between 1 and 8192
      tools: "function"  # Specify tools if applicable
      tool_choice: "auto"  # "none", "auto", or specific tool name
      top_p: 0.95  # Float between 0 and 1
      logprobs: false  # Boolean
      top_logprobs: 5  # Integer between 0 and 20
      available_models:
        - "deepseek-chat"
        - "deepseek-reasoner"


    Anthropic:
      text_model: "claude-3-sonnet-20240229"  # Default text_model
      temperature: 0.7  # Adjusts randomness (0 = strict, 1 = creative)
      max_tokens: 500  # Max tokens allowed per response
      top_p: 0.9  # Nucleus sampling (alternative to temperature)
      frequency_penalty: 0.0  # Controls repetition
      presence_penalty: 0.0  # Encourages new topics
      stop_sequences: []  # List of custom stop sequences
      system: "You're a professional copywriter helping turn blog posts into viral LinkedIn content."
      available_models:
        - "claude-3-7-sonnet-20250219"
        - "claude-3-5-haiku-20241022"
        - "claude-3-5-sonnet-20241022"
        - "claude-3-5-sonnet-20240620"
        - "claude-3-opus-20240229"
        - "claude-3-sonnet-20240229"
        - "claude-3-haiku-20240307"
      message_format:
        - role: "user"
          content: "Hello, world"

    HuggingFace:
        text_model: "mistralai/Mistral-7B-Instruct-v0.1"
        image_model: "runwayml/stable-diffusion-v1-5"
        video_model: "runwayml/stable-diffusion-v1-5"
        temperature: 0.7
        max_tokens: 500
        available_models:
          - "meta-llama/Meta-Llama-3-8B"
          - "mistralai/Mistral-7B-Instruct-v0.1"
          - "tiiuae/falcon-7b-instruct"
        available_tools:
          - "Audio Classification"
          - "Automatic Speech Recognition"
          - "Chat Completion"
          - "Feature Extraction"
          - "Fill Mask"
          - "Image Classification"
          - "Image Segmentation"
          - "Image to Image"
          - "Image-Text to Text"
          - "Object Detection"
          - "Question Answering"
          - "Summarization"
          - "Table Question Answering"
          - "Text Classification"
          - "Text Generation"
          - "Text to Image"
          - "Token Classification"
          - "Translation"
          - "Zero Shot Classification"
      # Cohere:
      #   enabled: false
      #   text_model: "command-r"
      #   temperature: 0.7
      #   max_tokens: 500
      #   available_models:
      #     - "command-r-plus"
      #     - "command-r"

      # Ollama:
      #   enabled: false
      #   text_model: "llama3:8b"
      #   temperature: 0.7
      #   max_tokens: 500
      #   available_models:
      #     - "llama3:8b"
      #     - "llama3:70b"
      #     - "mistral:7b"



    Custom:
      enabled: false
      text_model: "your-custom-text_model"
      temperature: 0.7
      max_tokens: 500
      url: "https://your-custom-api.com/v1/completions"
      headers:
        Authorization: "Bearer your_api_key"
        Content-Type: "application/json"
  # ✅ Creative Preferences (Visuals & Storytelling)


# ✅ Social Media Platforms
social_media_to_post_to:
  linkedin:
    enabled: true
    post_format: "Text"  # Options: Markdown, HTML, or None
    maximum_characters: 1300  # Maximum number of characters allowed
    maximum_characters: 2000  # Maximum number of characters allowed

# ✅ OpenAI Configuration & Content Generation
ai:
  default_response_instructions: "Return EITHER a generated JSON image (Creative and ImageAsset) if a creative prompt is provided OR GifSearchTags if not—never both. Example response: { \"Text\": \"Your message here.\", \"Creative\": \"[IMG] A relevant visual description.\", \"ImageAsset\": \"https://image.pollinations.ai/prompt/{description}?width={width}&height={height}&seed={seed}&model=flux-realistic&nologo=true\", \"Hashtags\": [\"#Relevant\", \"#Contextual\", \"#GeneralTopic\"] } or { \"Text\": \"Message.\", \"Hashtags\": [\"#tag\", \"#tag\", \"#tag\"], \"GifSearchTags\": [\"term one\", \"term two\", \"term three\"] }"
  custom_system_instructions: "Return EITHER a generated JSON image (Creative and ImageAsset) if a creative prompt is provided OR GifSearchTags if not—never both. "
  custom_user_instructions: "Example response: { \"Text\": \"Your message here.\", \"Creative\": \"[IMG] A relevant visual description.\", \"ImageAsset\": \"https://image.pollinations.ai/prompt/{description}?width={width}&height={height}&seed={seed}&model=flux-realistic&nologo=true\", \"Hashtags\": [\"#Relevant\", \"#Contextual\", \"#GeneralTopic\"] } or { \"Text\": \"Message.\", \"Hashtags\": [\"#tag\", \"#tag\", \"#tag\"], \"GifSearchTags\": [\"term one\", \"term two\", \"term three\"] }"  # Optional user-level AI guidance

  text:
    generate_text:
      enabled: true
      user_description: "If true, generates a tailored AI Social Media Post and An Image Or Gif"
      prompt: "Create a high-quality AI-generated image relevant to the blog content."
      formatting_instructions: "\n\nIMPORTANT: Format the post with proper line breaks for readability. Put each list item on a new line, and ensure paragraph breaks where appropriate. Add line breaks before and after lists."
      LLM: "Pollinations_Text_Advanced"
      # Available models: 'Pollinations', 'OpenAi', 'HuggingFace', 'DeepSeek', 'Claude'
  creative:
    generate_image:
      enabled: true
      user_description: "If true, generates a fallback image if the prompt fails to create one"
      width: 1024,
      height: 1024,
      prompt: "Create a high-quality AI-generated image relevant to the blog content."
      LLM: "Pollinations_Image_Get" # HuggingFace, OpenAI, Pollinations_Image_Get, Pollinations_Image 
      # Hugging Face Models: https://huggingface.co/models?pipeline_tag=text-to-image  && Flux Models: 'flux', 'flux-realism', 'any-dark', 'flux-anime', 'flux-3d', 'turbo'
      
    fetch_gif:
      enabled: true
      user_description: "If true, ai suggests tags from giphy then pick the giph with the most relevant title"
      prompt: "return atleast 3 giphy search terms in the returned object in an array"

# (Coming SOON)
    generate_video:
      enabled: false
      user_description: "If true, includes a video in the LinkedIn post to boost engagement."
      prompt: "Generate a video that highlights the key points of the blog post."

  viral_posting:
    include_viral_formatting:
      enabled: true
      description: "Ensures AI-generated posts follow viral structures."
      
    attention_grabbing_intro:
      enabled: true
      description: "First sentence must hook the reader to capture attention."
      
    emotional_storytelling:
      enabled: true
      description: "Includes personal/emotional elements to increase relatability."
      
    extreme_statements:
      enabled: false
      description: "Uses bold statements to spark engagement/debate (if enabled)."
      
    relatable_experiences:
      enabled: true
      description: "Ensures the post connects with the audience's daily struggles."
      
    actionable_takeaways:
      enabled: true
      description: "Posts must offer practical insights or solutions for readers."
      
    data-backed_claims:
      enabled: true
      description: "Uses real data & examples to establish credibility and trust."

  viral_posts_i_liked:
    - text: "I've never seen so many Trust and Safety leaders speaking out on LinkedIn.\n\nThis has traditionally been such a quiet, discreet industry. The work is heavy, the challenges are immense, and the stakes couldn't be higher. For years, much of what happens in Trust and Safety has taken place behind the scenes, out of sight but vital to the safety of billions of users around the world.\n\nBut now, something has shifted. \n\nThese leaders are speaking out. It's not just because of what's happening with Meta, TikTok, or the latest headlines. It's because these issues are bigger than any one platform. This is about a fundamental shift in how Trust and Safety is being addressed, how platforms are held accountable, and how we protect people online.\n\nWhen these leaders take to LinkedIn to share their insights, their frustrations, or their hope, it's because they know the moment we're in matters. Their voices reflect the urgency of the challenges we're facing and the determination to find solutions that work, not just for platforms, but for society at large.\n\nIf you're seeing these conversations too, pay attention. \nWhen Trust and Safety leaders speak out, it's not just noise, it's a call to action."
      engagement: "314 likes 15 comments 13 reposts"
      creative: "None"
      creative_asset: ""
      reason: "This post is very human no excesive emojis  and connnecting tot he user directly"
    
    - text: "Facebook was built on PHP.\n\nAirbnb used Ruby on Rails. \n\nWhatsApp scaled to billions on Erlang.\n\nTech stack debates are the biggest time-wasters for early-stage founders.\n\nThe brutal truth:\n- 9 out of 10 startups fail before technical scaling is ever an issue \n- No customer has ever said:\n\"I would have used your product if it was built on [trendy framework]\"\n- The famous 2011 \"MongoDB is web scale\" parody video is STILL relevant today\n\nYC partner Gustaf Alströmer puts it perfectly: \n\"Your tech stack should be the most boring decision you make.\"\n\nFor early-stage validation: \n- Use languages your team already knows \n- Leverage existing tools/templates/libraries\n- Build for weeks, not months \n- Optimize for iteration speed, not scalability\n\nCraigslist is still running on Perl and makes $1B+ in annual revenue.\n\nWhen you have 1M users, hire a specialist. \n"
      engagement: "491 likes, 44 comments 19 reposts"
      creative: "None"
      creative_asset: ""
      reason: "Gives factual bases to start a conversation gives examples of other companies and why you should ship fast"

    - text: "People always say, \"Showing up is half the battle.\"\n\nBut in reality, it's more like 80%.\n\nIf you can consistently show up, you’ve already overcome the biggest obstacle to success.\n\nSo how do we make it feel automatic?\n\nThere are basically two levers we can pull:\n1. Make starting easier (duh).\n2. Make skipping harder.\n\nTo make starting easier, it all comes down to lowering the activation energy of whatever task you're trying to do.\n\nHere are 3 of my favorite ways to achieve this:\n\n○ The \"next tiny move\":\n   When you're stuck or overwhelmed, ask: What's my next tiny move? Not the whole project. Just the next step.\n\n○ Remove friction in advance:\n   Lay out your gym clothes the night before. Prep your meals on Sunday. Eliminate excuses before they show up.\n\n   Commit to your calendar:\n\n   What gets scheduled gets done. Block time for the things that matter—and honor it like any other appointment.\n\nTo make skipping harder, you need to make the discomfort of avoidance so high that going through with your commitment actually feels like the easier option.\n\nHere are 3 strategies I use:\n\n○ Commit financially:\n   Pay for a class, a course, or a coach in advance. Money is the ultimate motivator, use it to your advantage.\n\n○ Get an accountability buddy:\n   Find someone with a similar goal. Check in regularly. You’re less likely to ghost your goals if someone’s expecting you.\n\n○ Anti-rewards:\n   Set a consequence for skipping. If you miss your workout, you owe your friend $20…or worse, you donate to a cause you hate. Nothing lights a fire like a little pain.\n\nMake it easy to start.\nMake it hard to skip.\n\nDo that, and showing up becomes your default setting. ♻️ Repost this if you found it helpful."
      engagement: "5,991 likes, 583 comments 437 reposts"
      creative: "Image of twitter post about yoga class comparing it to starting being the hardest part"
      creative_asset: "https://media.licdn.com/dms/image/v2/D5622AQHbdQ2vMhAHIQ/feedshare-shrink_800/B56ZXXeT2BGQAg-/0/1743076804369?e=1746662400&v=beta&t=2g8qD07mbsyeCWJOCUhCyPgQGR3x1XBMbcQXYsX9CeY"
      reason: "Gives factual bases to start a conversation gives examples of other companies and why you should ship fast"
# ✅ Hashtags for Engagement
hashtags:
  default_tags:
    - "#AI"
    - "#MachineLearning"
    - "#DataScience"
    - "#Automation"
    - "#Technology"
  custom_tags: []  # Users can add their own custom hashtags here
